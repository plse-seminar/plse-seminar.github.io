- id: shaiful-eng
  title: "GreenBundle: An Empirical Study on the Energy Impact of Bundled Processing"
  presenter: Shaiful Chowdhury
  date: 2019-03-13 12:00:00
  abstract: "Energy consumption is a concern in the data-center and at the edge, on mobile devices such as smartphones. Software that consumes too much energy threatens the utility of the end-user's mobile device. Energy consumption is fundamentally a systemic kind of performance and hence it should be addressed at design time via a software architecture that supports it, rather than after release, via some form of refactoring. Unfortunately developers often lack knowledge of what kinds of designs and architectures can help address software energy consumption. In this paper we show that some simple design choices can have significant effects on energy consumption. In particular we examine the Model-View-Controller architectural pattern and demonstrate how converting to Model-View-Presenter with bundling can improve the energy performance of both benchmark systems and real world applications. We show the relationship between energy consumption and bundled and delayed view updates: bundling events in the presenter can often reduce energy consumption by 30%."

- id: karim-vul
  title: Scalable and Precise Security Vulnerability Detection
  presenter: Karim Ali
  date: 2019-02-27 12:00:00
  abstract: "Precise detection of security vulnerability requires static analyses that are context-sensitive, field-sensitive, and flow-sensitive. Context-sensitivity and field-sensitivity can both be expressed as context-free language (CFL) reachability problems. Solving both CFL problems along the same dataflow path is undecidable, which is why most flow-sensitive dataflow analyses over-approximate field-sensitivity by limiting the access path to a certain threshold k, or through access graphs. Unfortunately, both representations do not scale very well when used to analyze complex programs (e.g., programs that contain recursive data structures). Any single CFL-reachablity problem is efficiently solvable, by means of a pushdown system. In this work, we introduce the concept of synchronized pushdown systems (SPDS). SPDS encodes both procedure calls/returns and field stores/loads as separate but synchronized CFL reachability problems. An SPDS solves both individual problems precisely, and over-approximation occurs only in corner cases that we show are rare in practice. SPDS is also efficient: formal complexity analysis shows that SPDS shift the complexity from |F|^3k under k-limiting to |S| * |F|^2, where F is the set of fields and S the set of statements involved in a dataflow. Our evaluation shows that this improvement significantly pays off in practice. SPDS is almost as efficient as k-limiting with k=1 with a precision equals to the case where k is infinite. For a typestate analysis, SPDS accelerates the analysis up to 83x for dataflows of objects that involve many field accesses but span rather few methods."

- id: Curtis-agile
  title: Agile in Practice
  presenter: Curtis Onuczko (Bioware)
  date: 2019-02-13 12:00:00
  abstract: "What does agile look like when put into practice for game development? In this talk, Curtis Onuczko will go over the challenges of putting Agile into practice on his team at BioWare. He will also go over several real-world examples of strategies used to overcome those challenges. Working on video games can be a crazy and chaotic experience. With properly applied agile, teams can successfully navigate this chaos and deliver truly valuable software."

- id: cor-game
  title: How can game developers leverage data from online distribution platforms? A case study of the Steam platform
  presenter: Cor-Paul Bezemer (ECE, Ualberta)
  date: 2019-01-30 12:00:00
  abstract: "Computer games are a rapidly growing application genre. With a projected revenue of almost $138 billion in 2018, the gaming industry has significantly outgrown other popular entertainment industries, such as the movie industry. To ensure that a game meets the high and ever-changing expectations of the gaming community, it is essential to take into account the feedback of gamers throughout the game development and maintenance processes. Traditionally, such feedback has been difficult to acquire. However, the recent trend of digitally distributing games has improved the process of providing and collecting feedback. For example, digital distribution platforms allow users to buy, download, and review tens of thousands of PC games (e.g., through the Steam platform) and hundreds of thousands of mobile game apps (e.g., through the Google Play store). In addition to feedback, these platforms contain large amounts of metadata about the software engineering processes of these games, such as their release schedule and issue reports. In my research, my students and I focus on mining these online distribution platforms for games. In this talk, I will give an overview of our research on the Steam platform, the largest digital distribution platform for PC gaming, with more than 30,000 available games and more than 184 million active users. In particular, I will explain what type of useful data we can retrieve from such platforms, and I will discuss how game developers can leverage this data."

- id: shadan-sim
  title: Simulation-Based Deployment Configuration of Smart Homes
  presenter: Shadan Golestan-Irani
  date: 2019-01-16 12:00:00
  abstract: "Evaluating Wireless Sensor Network (WSN) deployment scenarios for sensor–driven applications is a tedious and labour–intensive task. To mitigate the cost involved with comparatively evaluating alternative deployments, we present an integrated methodology that enables the modeling, simulation, and evaluation of alternative candidate WSN deployments, as well as, the fine–tuning of the corresponding sensor–driven applications. Based on our previous experience on indoor occupant localization and activity recognition, we illustrate our methodology by applying it to the task of deploying an ambient intelligence application. We explain how our methodology models the real–world environment and the candidate WSN deployment, simulates the occupants’ activities and the WSN run-time behavior, and evaluates, through a variety of metrics, the effectiveness of the application under different deployment configurations. We demonstrate our methodology on two real–world localization application scenarios corresponding to two, drastically different, spaces."

- id: ali-energy
  title: Saving smartphone battery life through software engineering
  presenter: Abdul Ali Bangash
  date: 2018-12-05 12:00:00
  abstract: "With the widespread use of mobile devices relying on limited battery power, the burden of optimizing applications for energy has shifted towards the application developers. In their quest to develop energy efficient applications, developers face the hurdle of measuring the effect of software change on energy consumption. A naive solution to this problem would be to have an exhaustive suite of test cases that are executed upon every change to measure their effect on energy consumption. This method is inefficient and also suffers from environment dependent inconsistencies. A more generalized method would be to relate software structural metrics with its energy consumption behavior. Previous attempts to relate change in object-oriented metrics to their effects on energy consumption have been inconclusive. We observe that structural information is global and executed tests are rarely comprehensive in their coverage, this approach is prone to errors. In this paper, we present a methodology to relate software energy consumption with software structural metrics considering the test case execution traces. Furthermore, we demonstrate that software structural metrics can be reliably related to energy consumption behavior of programs using several versions of three open-source iteratively developed android applications. We discover that by using our approach we are able to identify strong correlations between several software metrics and energy consumption behavior."

- id: monica-repos
  title: Exploring Software Library Metrics using Repository Badges
  presenter: Monica Bui
  date: 2018-12-05 12:00:00
  abstract: "Libraries, Frameworks, and Application Programming Interfaces (APIs) provide users a way to reuse existing functionalities written within the library itself. Using libraries allows users to focus on their own work more effectively instead of implementing existing features from scratch. With many libraries out there, it is often not clear how to select the best one to use for your project. Here, we look into quantitative software metrics that exert a library's inner qualities such as build status and test code coverage and turn them into visual repository badges. These repository badges are frequently found in README files and provides an accessible way for users to compare metrics between libraries to help determine the best fit for their work. We will focus on new and previously worked on metrics and how we transformed those into badges."

- id: ifzal-sybtyping
  title: Depth-subtyping and Mutation
  presenter: Ifaz Kabir
  date: 2018-11-21 12:00:00
  abstract: "In object-oriented languages, depth-subtyping is the idea that subtyping between two types implicitly introduce subtyping between classes with fields of those types. Object-oriented languages which support depth-subtyping (e.g. Scala) only allow depth-subtyping for fields which cannot be mutated. In this talk, I will discuss the challenges in simultaneously supporting mutation and depth-subtyping and propose a solution to this problem."

- id: kelvin-web
  title: (Semi)Automatic Construction of Access-Controlled Web Data Services
  presenter: Kalvin Eng 
  date: 2018-11-21 12:00:00
  abstract: "The widespread adoption of the Internet of Things (IoT) is producing an ever-increasing stream of data that can be mined by multiple stakeholders, in support of different objectives and tasks. In fact, we are witnessing the emergence of data marketplaces that aim to share this data and harness economic value out of these transactions. The advent of data-as-a-service (DaaS) represents a key integrator opportunity that allows for the management of data collections, while providing specific privacy policies to delegated agents. To support DaaS integrations, we develop a model-driven method for creating APIs to deliver DaaS. Our method supports data owners to: (1) automatically abstract the representation of relational database schemas into a visual model and map them to existing ontologies, (2) use the mappings in order to create different role-based access-control views of APIs, and (3) automatically generate API endpoints and their responses, based on these mappings. We develop a 'plug-and-play' prototype system for SQL databases to demonstrate this methodology and apply it to a use case of controlling data from a fitness monitoring application. Our aim is to enhance existing API creation methodologies that may be cumbersome by using semantics so that data can be easily shared and distributed."

- id: diego-vulkan
  title: Graphics Shader Languages - Compilation Challenges
  presenter: Diego Novillo (Google)
  date: 2018-10-10 12:00:00
  abstract: Graphics APIs have evolved in the last few years to the point where they require the presence of multiple levels of compilation, intermediate representations, and tools. This talk will provide an overview of graphics shader languages, intermediate representations, and the compilers used. The focus will be on the Vulkan ecosystem, challenges that need to be addressed, and the tools we are building to deal with them.

- id: revan-ml-se
  title: Fixing Machine Learning with Solver-aided Languages
  presenter: Revan MacQueen
  date: 2018-09-26 12:00:00
  abstract: "Machine learning has become increasingly ubiquitous in our modern world. Expanded computational power and more sophisticated algorithms have furthered the field to tackle an increasing variety of problems such as computer vision and predictive modeling. However, due to the complex nature of these algorithms, human understanding of the underlying processes of machine learning is limited. This discrepancy between human knowledge and the complexity of ML algorithms leads to a problem: when machine learning algorithms err, how do we fix them? As humans, adjusting the tens of thousands (or millions) of individual parameters in a neural network to correct poor performance is a seemingly impossible task due to the sheer size and  intricacy of these models. Our project is looking for a solution to this problem. We use SMT solvers to correct errors in machine learning prediction models, while maintaining the accuracy and generalization capacities of these models. In particular, we make use of the powerful solver-aided programming language Rosette to solve these complex optimization problems. Incredibly, Rosette is able to represent neural networks and their results as symbolic values, which can then be solved for under the assertion that a given data point is correct. Our goal is to be able to iteratively correct ML errors using this method."

- id: aida-nonfun
  title: Identifying Bugs Related to Non-Functional Requirements in Java and Python
  presenter: Aida Radu
  date: 2018-08-29 12:30:00
  abstract: Non-functional requirements describe quality attributes of a program, such as performance and security. While several researchers have published bug datasets in the past, there has been little focus on bugs related to non-functional requirements. In this presentation, we introduce NFBugs, a dataset of 138 non-functional bug fixes collected from 67 open source projects. We describe the layout of the dataset and the methods used to construct it. Our dataset is publically available on GitHub to encourage expansion and analysis.

- id: alex-delphi
  title: Automated Management of Static Analysis Benchmarks
  presenter: Alexander MacKenzie
  date: 2018-08-29 12:30:00
  abstract: The act of benchmarking of static analysis tools currently has some pitfalls. Projects used to benchmark these tools often must include certain features, such as specific statements or access patterns. The difficulty of finding appropriate projects means that developers of static analysis tools often handpick projects with these features for benchmarking, which is a time consuming process and limits how well benchmarking tests reflect real world applications of these tools. Together with our collaborators at the University of Paderborn and TU Darmstadt, we are currently developing a tool suite titled ABM (Automated Benchmark Management) to assist developers in constructing collections of projects with specific features. One component of ABM is Delphi, which scrapes open source projects off public repositories such as Maven Central, uses static analysis tools to generate a list of features included in these projects, saves the recorded features to an Elasticsearch database, and allows users to search for projects that include certain features.  This talk details the implementation of a component of Delphi that uses static analysis to record all methods in external libraries that are called by a given project, along with which libraries each method belongs to. To accomplish this, lists of external calls are generated for libraries hosted on Maven Central, then these external calls are mapped onto the libraries that define them and posted to the database. This database will then be accessed through either a web API or a CLI. Such a workflow will allow users to use Delphi to find open source projects that use certain libraries or methods of interest, and analyse real-world usages of these libraries without having to handpick a selection of projects that are known to use these libraries.

- id: jacob-varcpp
  title: Variability-Aware of C++ Code Using Clang
  presenter: Jacob Reckhard
  date: 2018-08-15 12:30:00
  abstract: In the C family of languages, lexical preprocessors are prevalent as a method to introduce variation into code. While these lexical preprocessors facilitate portability and code reuse, they introduce additional complexity which can make it challenging for traditional tools to analyze code. Tool-based analysis is important to catch errors before the codebase becomes too dependent on the erroneous parts. One well known project for compilation and analysis of code is Clang. In this presentation, we describe the changes required to coerce Clang into conducting variability-aware analysis of C++ code. Varibility-aware analysis is a technique in which the code base is analysed for all possible configurations of the code. In the process we show a novel approach to conducting variability-aware parsing in a sound manner using an existing C++ parser that doesn't suffer from unnecessary exponential time growth.

- id: erick-nix
  title: How can Nix package manager help you with your research?
  presenter: Erick Ochoa
  date: 2018-08-15 12:00:00
  abstract: Nix’s purely functional approach ensures that installing or upgrading one package cannot break other packages. This is because it won’t overwrite dependencies with newer versions that might cause breakage elsewhere. It allows you to roll back to previous versions, and ensures that no package is in an inconsistent state during an upgrade. Nix builds packages in isolation from each other. This ensures that they are reproducible and don’t have undeclared dependencies, so if a package works on one machine, it will also work on another. What does this mean for your research? Do you have multiple projects that use different versions of the same library? Do you want different developer environments for different projects? Do you want to specify dependencies at runtime? Accidentally <code>rm /</code> your machine and need to install your dependencies? Do you want to fully specify the environment in which your experiment runs? Do you want someone else to run your experiment easily?

- id: kristen-crypto
  title: Detecting Misuses of Crypto APIs
  presenter: Kristen Newbury
  date: 2018-08-01 12:00:00
  abstract: Static analysis is an invaluable technique for approximating the runtime behaviour of programs. However, as an approximation, static analysis may not be able to eliminate consideration of code paths and states that will not be encountered during typical program execution. While over-approximation may not significantly impact performance when analyzing small applications, it may be difficult to achieve scalable performance of static analysis tools on codebases that are large or are comprised of (object oriented) languages with features such as dynamic dispatch. To be valuable to developers, modern static analysis tools must focus on simultaneously delivering soundness, precision, and speed. Analyses that leverage runtime information may be able to improve their performance by increasing the precision of their analysis. Application security is an area of computing that can benefit from program analysis. Many applications are required to securely deal with cryptographic tasks such as file encryption, password hashing, and storing and authenticating user logins. However, the average developer is not a cryptography expert, and, therefore, must rely on Application Programming Interfaces (APIs) to meet their applications' security needs. In spite of this modularity, it is still possible to use an API incorrectly, which may result in significant monetary loss and reputation damage to individuals and corporations. Program analysis tools such as Cognicrypt (an Eclipse plugin) have been developed specifically to aid developers with crypto API misuse detection.   This talk will look further into existing crypto API misuses detection technology as well as the motivations of investigating the integration of cryptography API misuse detection into a Just-in-Time context.

- id: andrew-ibm
  title: Compiler Development at IBM
  presenter: Andrew Craik (IBM)
  date: 2018-07-23 13:00:00
  abstract: Over the last two years IBM has open-sourced its JVM implementation and the framework used to build that JVM through the Eclipse OpenJ9 and Eclipse OMR projects respectively. In this talk, I’ll give an overview of compiler development at IBM, the Eclipse OMR and Eclipse OpenJ9 projects, IBM’s open source approach to JVM development, and some of the areas of innovation in these projects. At the conclusion of this overview, I will take a deep dive into one of our current enhancement projects – JProfiling. JProfiling is an innovative software-based profiling framework which gathers high precision execution frequency and program value information with low overheads – preliminary evaluation suggests an overhead of approximately 30% throughput compared to existing techniques which incur overheads in excess of 80%.

- id: samer-varcpp
  title: Supporting Software Variability in C++
  presenter: Samer Al Masri
  date: 2018-07-18 13:00:00
  abstract: As software becomes more common in our daily lives, software is now expected to have multiple features and work in different enviroments. One example is Eclipse OMR, a C++ library of language runtime components. OMR supports multiple architectures and various langages and hence it is considered a software family. Aiming to facilitate the development of software families in general and OMR more specifically, we created OMRStatistics, a static analysis tool that helps Eclipse OMR developers collect statistics about the project and make development decisions about variability. In this talk, I will be explaining the motivation behind OMRStatistics, what problems it contribute to solving, and the impact that we are aiming to obtain with the help of this tool.

- id: rene-method1
  title: A New Enterprise Software Paradigm
  presenter: Rene Kohut (Method1)
  date: 2018-07-04 13:00:00
  abstract: Technology is advancing at incredible speeds but advancements in enterprise software implementation practices have been left behind. As a result, significant resource inefficiencies and subsequent negative economic impacts are becoming the norm. This presentation shares insights into industry related issues as observed by Method1 Enterprise Software and proposes a new paradigm aimed at making sweeping industry change.

- id: ali-bugs
  title: Thesaurus and Time Based Bug Assignment
  presenter: Ali Sajedi
  date: 2018-06-20 13:00:00
  abstract: Bug-assignment, the task of ranking developers in terms of the relevance of their expertise to fix a new bug report is time consuming, which is why substantial attention has been paid to developing methods for automating it. In this talk, we describe our new bug-assignment approach that relies on two key intuitions. Similar to traditional bug-assignment methods, our method constructs the expertise profile of project developers, based on the textual elements of the bugs they have fixed in the past; unlike traditional methods, however, our method considers only the programming keywords in these bug descriptions, relying on Stack Overflow as the thesaurus for these keywords. The second key intuition of our method is that recent expertise is more relevant than past expertise, which is why our method weighs the relevance of a developer’s expertise based on how recently they have fixed a bug with keywords similar to the bug at hand. We evaluated our BA method using a data set of 93k bug-report assignments from thirteen popular Github projects and show that our method outperforms state-of-the-art methods.

- id: rameel-cnns
  title: Training Deep Convolutional Networks with Unlimited Synthesis of Musical Examples for Multiple Instrument Recognition
  presenter: Rameel Sethi
  date: 2018-06-06 13:00:00
  abstract: Deep learning has been widely adopted in music information retrieval (MIR) after finding success in several other domains such as computer vision. However, content-based MIR often suffers from a lack of training data and/or labels, especially at the audio analysis frame level. This talk discusses one method of overcoming the scarcity of labeled recordings through generation of synthetic music compositions as training examples for deep convolutional networks applied to music classification. In particular, we investigate the MIR tasks of polyphony estimation and instrument recognition in polyphonic recordings where multiple instruments may be sounding simultaneously.

- id: thierry-synopsys
  title: "Static Analysis For Security: How Coverity Does It"
  presenter: Thierry Lavoie (Synopsys)
  date: 2018-05-23 13:00:00
  abstract: Software security used to be the arcane knowledge of a selected few software engineers, and a distinct and optional part of the software development cycle. With the wide publicity given to vulnerabilities like Heartbleed, Cloudbleed, Meltdown, and Spectre, this once obscure domain has been made mundane. However, while public awareness of security issues has increased, their frequency and impact have not proportionally decreased. Many companies actively seek solutions to identify, address, and prevent security threats within their product. As a mature and market leading static analysis tool, Coverity is naturally suited to report and help in remediating security issues as part of the software development cycle. This talk will explain some of the techniques used by Coverity as well as its philosophical approach to static analysis as an industrial tool.

- id: andrew-cisco
  title: Advanced Malware Protection
  presenter: Andrew Neitsch (Cisco)
  date: 2018-04-11 13:00:00
  abstract: "Cisco Systems has an engineering office in Calgary with more than 100 people building the Advanced Malware Protection product. This talk will give an introduction to the current computer security landscape; the universe of protection products; what AMP is; and some of the technical details and challenges of the specific work that the speaker does day-to-day: developing and supporting backend cloud data services that handle billions of requests per day."

- id: susan-jobber
  title: Why Style Matters
  presenter: Susan Wright (Jobber)
  date: 2018-03-28 13:00:00
  abstract: A talk about coding style including real world examples, both good and bad. Learn how coding style can impact projects and collaboration, and uncover examples of tools that can be used to help enforce style guides. Finally, discover why a style guide isn’t written in stone and how adjustments can be made.

- id: shaiful-greenscaler
  title: "GreenScaler: Training Software Energy Models With Automatic Test Generation"
  presenter: Shaiful Chowdhury
  date: 2018-03-14 13:00:00
  abstract: Software energy consumption is a performance related non-functional requirement that complicates building software on mobile devices today. Energy hogging applications (apps) are a liability to both the end-user and software developer. Measuring software energy consumption is non-trivial, requiring both equipment and expertise, yet researchers have found that software energy consumption can be modelled. Prior works have hinted that with more energy measurement data we can make more accurate energy models. This data, however, was expensive to extract because it required energy measurement of running test cases (rare) or time consuming manually written tests. We address these concerns by automatically generating test cases to drive apps undergoing energy measurement. Automatic test generation allows a model to be continuously improved in a model building process whereby apps are extracted, tests are generated, energy is measured and combined with instrumentation to train a model of software energy consumption. This continuous process has allowed the authors to generate and extract measurements from hundreds of apps in order to build accurate energy models capable of predicting the energy consumption of apps without end-user energy measurement. We clearly show that we can reduce energy modelling error of models built from more apps through this automatic test generation process. Also, the produced models are very accurate in detecting energy regression between versions of the same app. This is directly helpful for the app developers who want to know if a change in the source code, for example, is harmful for the total energy consumption.

- id: jeff-swift
  title: Enabling Swift analyses in WALA Generation
  presenter: Jeff Cho
  date: 2018-03-14 13:30:00
  abstract: Swift, Apple's open-source programming language, is increasing in popularity and usage for creating applications for Apple platforms including iOS  and macOS.  However, the low-level LLVM-based tooling that Apple provides is not readily usable by researchers who conduct higher-level program analyses, and current research frameworks have little support for Swift applications, even though they provide extensive support for other platforms such as Android. The Swift-WALA project's goal is to enable the research and analysis of Swift applications using IBM's T.J. Watson Libraries for Analysis (WALA). The project has been part of the Undergraduate Capstone Open Source Project (UCOSP) for the past two semesters, working with students from across Canada who have built support for a number of basic instruction types. The presentation will discuss some of the technical details, approaches attempted, progress made, and challenges encountered thus far by the Swift-WALA team.

- id: mehran-android
  title: "The Android Update Problem: An Empirical Study"
  presenter: Mehran Mahmoudi
  date: 2018-02-28 13:00:00
  abstract: Many phone vendors use Android as their underlying OS, but often extend it to add new functionality and to make it compatible with their specific phones. When a new version of Android is released, phone vendors need to merge or re-apply their customizations and changes to the new release. This is a difficult and time-consuming process, which often leads to late adoption of new versions. In this paper, we perform an empirical study to understand the nature of changes that phone vendors make, versus changes made in the original development of Android. By investigating the overlap of different changes, we also determine the possibility of having automated support for merging them. We develop a publicly available tool chain, based on a combination of existing tools, to study such changes and their overlap. As a proxy case study, we analyze the changes in the popular community-based variant of Android, LineageOS, and its corresponding Android versions. We investigate and report the common types of changes that occur in practice. Our findings show that 83% of subsystems modified by LineageOS are also modified in the next release of Android. By taking the nature of overlapping changes into account, we assess the feasibility of having automated tool support to help phone vendors with the Android update problem. Our results show that 56% of the changes in LineageOS have the potential to be safely automated.

- id: ben-tasks
  title: Creating Task-oriented Summaries of APIs from Crowdsourcing Websites
  presenter: Benyamin Noori
  date: 2018-02-14 13:00:00
  abstract: Community crowdsourcing websites are a popular source of information for software developers. Stack Overflow, being a prominent online resource for programmers, hosts almost 15 million programming questions and answers. In this paper, we introduce a novel approach that uses the data gathered from Stack Overflow to build a task-oriented summary of a given software library. This summary can be used to help developers learn how to accomplish everyday tasks. We evaluate the usefulness of this approach using a survey of computer science students.

- id: stephen-deepgreen
  title: "Deep Green: Modelling Time-Series of Software Energy Consumption"
  presenter: Stephen Romansky
  date: 2018-01-31 13:00:00
  abstract: Inefficient mobile software kills battery life. Yet, developers lack the tools necessary to detect and solve energy bugs in software. In addition, developers are usually tasked with the creation of software features and triaging existing bugs. This means that most developers do not have the time or resources to research, build, or employ energy debugging tools.  We present a new method for predicting software energy consumption to help debug software energy issues. Our approach enables developers to align traces of software behavior with traces of software energy consumption. This allows developers to match run-time energy hot spots to the corresponding execution. We accomplish this by applying recent neural network models to predict time series of energy consumption given a software’s behavior. We compare our time series models to prior state-of-the-art models that only predict total software energy consumption. We found that machine learning based time series based models, and LSTM based time series based models, can often be more accurate at predicting instantaneous power use and total energy consumption.

- id: erick-inliner
  title: Using Static Information to Improve Inlining Decisions
  presenter: Erick Ochoa
  date: 2018-01-31 13:30:00
  abstract: Function inlining is a well known technique for speeding up programs. By eliminating the need of pushing/popping arguments into/from the stack, function inlining can decrease the execution time of function calls. Time savings add up quickly when function inlining is applied to frequently visited call sites. Under this logic, the optimal decision is to apply function inlining to call sites that are visited the most. However, time savings obtained from these benefits are often overshadowed by those obtained by enabling other compiler optimization. After a function is inlined, its body is available in the caller's context and we say that the function has been specialized to its calling context. This suggests that call frequency should not be the only deciding factor in inlining. Static information that allows the compiler to perform other optimizations safely should also be taken into account. In this talk, we will go over how abstract interpretation can be used to safely estimate other compiler optimizations and how this can improve inlining decision.

- id: eddie-syntax
  title: "Syntax and Sensibility: Using language models to detect"
  presenter: Eddie Santos
  date: 2018-01-17 13:00:00
  abstract: Syntax errors are made by novice and experienced programmers alike; however, novice programmers lack the years of experience that help them quickly resolve these frustrating errors. Standard LR parsers are of little help, typically resolving syntax errors and their precise location poorly. We propose a methodology that locates where syntax errors occur, and suggests possible changes to the token stream that can fix the error identified. This methodology finds syntax errors by using language models trained on correct source code to find tokens that seem out of place. Fixes are synthesized by consulting the language models to determine what tokens are more likely at the estimated error location. We compare n-gram and LSTM (Long short-term memory) language models for this task, each trained on a large corpus of Java code collected from GitHub. Unlike prior work, our methodology does not rely that the problem source code comes from the same domain as the training data. We evaluated against a repository of real student mistakes. Our tools are able to find a syntactically-valid fix within its top 2 suggestions, often producing the exact fix that the student used to resolve the error. The results show that this tool and methodology can locate and suggest corrections for syntax errors. Our methodology is of practical use to all programmers, but will be especially useful to novices frustrated with incomprehensible syntax errors.

- id: fernando-libs
  title: Metric-Based Comparison of Software Libraries
  presenter: Fernando Lopez de la Mora
  date: 2018-01-17 13:30:00
  abstract: Software libraries ease development tasks by allowing client developers to reuse code written by third parties. To perform a specific task, there is usually a large number of libraries that offer the desired functionality. Unfortunately, selecting the appropriate library to use is not straightforward since developers are often unaware of the advantages and disadvantages of each library, and may also care about different characteristics in different situations. We introduce the idea of using software metrics to help developers choose the libraries most suited to their needs. We created library comparisons based on several metrics extracted from multiple sources such as software repositories, issue tracking systems, and Q&A websites. By consolidating all of this information in a single website, we enable developers to make informed decisions by comparing metric data belonging to libraries from several domains.
